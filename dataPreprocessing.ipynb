{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I isolate the data preprocessing process in my implementation of Unrolled Optimization with Deep Priors \n",
    "\n",
    "Note that this code was adapted based on work from this [source](https://github.com/Zhengqi-Wu/Unrolled-optimization-with-deep-priors/blob/master/README.md) as well as chatGPT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outline of notebook: \n",
    "\n",
    "Run these steps on the BSDS500 dataset \n",
    "\n",
    "start with the 400 image data set\n",
    "scale the input images to 0,255\n",
    "crop them to 180x180\n",
    "randomly flip or rotate images by 90 degrees, to increase the size of the dataset \n",
    "save that dataset as the y, original \n",
    "add noise to all the images, with noise variation =25\n",
    "\n",
    "\n",
    "Ensure you get the results you expect by \n",
    "\n",
    "* counting the number of output images \n",
    "* ensuring the images are cropped, scaled \n",
    "* compare an original image with its noisy counterpart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset \n",
    "# Define the paths to the BSD500 dataset\n",
    "data_dir = 'BSDS500/data/images'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "val_dir = os.path.join(data_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNoise(img, var):\n",
    "    noise = np.random.normal(scale=noise_var, size=img.shape).astype(np.int16)\n",
    "    img_noisy = np.clip(img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "    return img_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired image size and noise variation\n",
    "img_size = (180, 180)\n",
    "noise_var = 25\n",
    "\n",
    "convertToGrey = True\n",
    "\n",
    "original_images = []\n",
    "noisy_images = []\n",
    "\n",
    "input_dir = train_dir\n",
    "\n",
    "# Iterate over all images in the input directory\n",
    "for img_name in os.listdir(input_dir):\n",
    "    # Load the input image\n",
    "    img_path = os.path.join(input_dir, img_name)  \n",
    "    if img_path[-3:] != \"jpg\":\n",
    "            continue\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Convert to grayscale \n",
    "    if convertToGrey == True:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Scale the image to 0-255 range and crop to desired size\n",
    "    img = (img - img.min()) / (img.max() - img.min()) * 255\n",
    "    img = img.astype(np.uint8)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    \n",
    "\n",
    "    # Randomly flip or rotate the image\n",
    "    rand_num = np.random.randint(0, 6)\n",
    "    if rand_num == 0:\n",
    "        img1 = cv2.flip(img, 0)\n",
    "        imgnoisy1 = addNoise(img1, var=noise_var)\n",
    "        imgnoisy = addNoise(img, var=noise_var)\n",
    "        original_images.append(img)\n",
    "        original_images.append(img1)\n",
    "        noisy_images.append(imgnoisy)\n",
    "        noisy_images.append(imgnoisy1)\n",
    "    elif rand_num == 1:\n",
    "        img1 = cv2.flip(img, 1)\n",
    "        imgnoisy1 = addNoise(img1, var=noise_var)\n",
    "        imgnoisy = addNoise(img, var=noise_var)\n",
    "        original_images.append(img)\n",
    "        original_images.append(img1)\n",
    "        noisy_images.append(imgnoisy)\n",
    "        noisy_images.append(imgnoisy1)\n",
    "    elif rand_num == 2:\n",
    "        img1 = np.rot90(img)\n",
    "        imgnoisy1 = addNoise(img1, var=noise_var)\n",
    "        imgnoisy = addNoise(img, var=noise_var)\n",
    "        original_images.append(img)\n",
    "        original_images.append(img1)\n",
    "        noisy_images.append(imgnoisy)\n",
    "        noisy_images.append(imgnoisy1)\n",
    "    else: \n",
    "    # Add noise to the image\n",
    "        original_images.append(img)\n",
    "        noisy_images.append(img_noisy)\n",
    "\n",
    "original_images = np.array(original_images, dtype=np.float32)\n",
    "noisy_images = np.array(noisy_images, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'size of datasets \\n original {np.shape(original_images)} \\n noisy {np.shape(noisy_images)}')\n",
    "img = original_images[10,:,:]\n",
    "noisy_img = noisy_images[10,:,:]\n",
    "print(f'scale of original image {img.min(), img.max()} \\n scale of noisy image {noisy_img.min(), noisy_img.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(noisy_img, cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the above code in a function, so we can apply it to the training, testing and validation datatsets. Then, let's save all the datasets as numpy arrays to load later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessDataDirectory(inputDir, \n",
    "    saveString, \n",
    "    convertToGrey = True,\n",
    "    img_size = (180, 180),\n",
    "    noise_var = 25):\n",
    "\n",
    "    original_images = []\n",
    "    noisy_images = []\n",
    "\n",
    "    # Iterate over all images in the input directory\n",
    "    for img_name in os.listdir(inputDir):\n",
    "        # Load the input image\n",
    "        img_path = os.path.join(inputDir, img_name)  \n",
    "        if img_path[-3:] != \"jpg\":\n",
    "                continue\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Convert to grayscale \n",
    "        if convertToGrey == True:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Scale the image to 0-255 range and crop to desired size\n",
    "        img = (img - img.min()) / (img.max() - img.min()) * 255\n",
    "        img = img.astype(np.uint8)\n",
    "        img = cv2.resize(img, img_size)\n",
    "        \n",
    "\n",
    "        # Randomly flip or rotate the image\n",
    "        rand_num = np.random.randint(0, 6)\n",
    "        if rand_num == 0:\n",
    "            img1 = cv2.flip(img, 0)\n",
    "            imgnoisy1 = addNoise(img1, var=noise_var)\n",
    "            imgnoisy = addNoise(img, var=noise_var)\n",
    "            original_images.append(img)\n",
    "            original_images.append(img1)\n",
    "            noisy_images.append(imgnoisy)\n",
    "            noisy_images.append(imgnoisy1)\n",
    "        elif rand_num == 1:\n",
    "            img1 = cv2.flip(img, 1)\n",
    "            imgnoisy1 = addNoise(img1, var=noise_var)\n",
    "            imgnoisy = addNoise(img, var=noise_var)\n",
    "            original_images.append(img)\n",
    "            original_images.append(img1)\n",
    "            noisy_images.append(imgnoisy)\n",
    "            noisy_images.append(imgnoisy1)\n",
    "        elif rand_num == 2:\n",
    "            img1 = np.rot90(img)\n",
    "            imgnoisy1 = addNoise(img1, var=noise_var)\n",
    "            imgnoisy = addNoise(img, var=noise_var)\n",
    "            original_images.append(img)\n",
    "            original_images.append(img1)\n",
    "            noisy_images.append(imgnoisy)\n",
    "            noisy_images.append(imgnoisy1)\n",
    "        else: \n",
    "        # Add noise to the image\n",
    "            original_images.append(img)\n",
    "            noisy_images.append(img_noisy)\n",
    "\n",
    "    original_images = np.array(original_images, dtype=np.float32)\n",
    "    noisy_images = np.array(noisy_images, dtype=np.float32)\n",
    "\n",
    "    np.save(saveString+'_original_array.npy', original_images)\n",
    "    np.save(saveString+'_noisy_array.npy', noisy_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessDataDirectory(inputDir=test_dir, \n",
    "#     saveString='test')\n",
    "\n",
    "preprocessDataDirectory(inputDir=train_dir, \n",
    "    saveString='train')\n",
    "\n",
    "preprocessDataDirectory(inputDir=val_dir, \n",
    "    saveString='val')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
